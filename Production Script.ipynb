{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic Packages\n",
    "\n",
    "import time\n",
    "from math import sqrt, pi\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "## Sklearn packages\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "## Spotipy packages (Spotify API)\n",
    "\n",
    "import spotipy.oauth2\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import spotipy.util as util\n",
    "import spotipy\n",
    "\n",
    "## Importing Bokeh to explore outliers\n",
    "\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "import bokeh.models as bmo\n",
    "from bokeh.palettes import d3\n",
    "from bokeh.models import Legend, BoxSelectTool, BoxZoomTool, LassoSelectTool\n",
    "import bokeh.plotting as bpl\n",
    "from bokeh.embed import file_html, components, autoload_static\n",
    "import bokeh.embed as bem\n",
    "from bokeh.resources import CDN\n",
    "\n",
    "## Notebook display settings\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "## Audio feature descriptions\n",
    "\n",
    "#https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-297-75d88d7113a5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-297-75d88d7113a5>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    sp_username = **USERNAME**\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sp_username = **USERNAME**\n",
    "sp_client_id = **ID**\n",
    "sp_client_secret = **SECRET**\n",
    "sp_redirect_uri = **URI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1912,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token = util.prompt_for_user_token(username = sp_username, client_id= sp_client_id,client_secret= sp_client_secret,redirect_uri=sp_redirect_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1795,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spotipy.Spotify(auth=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Related to API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_search_artist(sp_artist_name):\n",
    "        ## Takes user name from user input and searches for artist information - returns dataframe\n",
    "        artist_search_results = sp.search(q = sp_artist_name, limit = 1, type = 'artist')\n",
    "        artist_search_results_2 = artist_search_results['artists']\n",
    "        artist_search_results_3 = artist_search_results_2['items']\n",
    "        sp_search_artists_df = pd.DataFrame(artist_search_results_3)\n",
    "        return sp_search_artists_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_search_track(sp_track_id):\n",
    "        ## Takes user name from user input and searches for artist information - returns dataframe\n",
    "        track_search_results = sp.search(q = sp_track_id, limit = 10, type = 'track')\n",
    "        track_search_results_2 = track_search_results['track']\n",
    "        track_search_results_3 = track_search_results_2['items']\n",
    "        sp_search_track_df = pd.DataFrame(track_search_results_3)\n",
    "        return sp_search_track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_search_album(sp_artist_id):\n",
    "        ## Search for albums based on artist ID\n",
    "        album_search_results = sp.artist_albums(sp_artist_id, album_type = 'album')\n",
    "        album_search_results_2 = album_search_results['items']\n",
    "        sp_search_album_df = pd.DataFrame(album_search_results_2)       \n",
    "        return sp_search_album_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_search_track(album, alb_num, rel_date):\n",
    "        ## Function that utilizes Spotify's album_tracks method to return all tracks from an album ID\n",
    "        track_search_results = sp.album_tracks(album, limit = 50)\n",
    "        track_search_results_2 = track_search_results['items']\n",
    "        sp_search_track_df = pd.DataFrame(track_search_results_2)\n",
    "        sp_search_track_df['album_name'] = alb_num\n",
    "        sp_search_track_df['release_date'] = rel_date\n",
    "        return sp_search_track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_features_audio(song_list):\n",
    "        ## Function that utilizes Spotify's audio_features method to return audio features (energy, tempo, etc)\n",
    "        audio_features_results = sp.audio_features(tracks = song_list)\n",
    "        audio_df = pd.DataFrame(audio_features_results)\n",
    "        return audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_track_analysis(song_list):\n",
    "        ## Function that utilizes Spotify's audio_features method to return audio features (energy, tempo, speechiness, etc)\n",
    "        audio_analysis_list = []\n",
    "        for i in range(len(song_list)):\n",
    "            results = sp.audio_analysis(song_list[i])\n",
    "            audio_analysis_list.append(results)\n",
    "        track_df = pd.DataFrame(audio_analysis_list)\n",
    "        return track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_track_info(song_list):\n",
    "        track_info_results = sp.tracks(song_list)\n",
    "        track_info_df = pd.DataFrame(track_info_results['tracks'])\n",
    "        return track_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General functions (not related to Spotify API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stats (column, df):\n",
    "    count_list = []\n",
    "    for row in range(len(df)):\n",
    "        count = 0\n",
    "        for item in range(len(df.iloc[row, column])):\n",
    "            count += 1\n",
    "        count_list.append(count)\n",
    "    return count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that takes a dataframe and iterates through columns to calculate predicted value\n",
    "\n",
    "def future_value(df, req_feat):\n",
    "    ## Will iterate through columns to calculate future value\n",
    "    requested_df = df[df.feature == req_feat]\n",
    "\n",
    "    x_reg = np.array(requested_df.album_number)\n",
    "    y_reg = np.array(requested_df.value)\n",
    "\n",
    "    fit = np.polyfit(x_reg, y_reg, 1)\n",
    "    fit_fn = np.poly1d(fit) \n",
    "\n",
    "    ## Fit the linear regression model to the expected 14th value\n",
    "    return fit_fn(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to normalize features\n",
    "\n",
    "def feature_norm(df, col):\n",
    "    return(df[col] - df[col].min())/(df[col].max() - df[col].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataframes from API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search for artist by input\n",
    "\n",
    "#artist_search_df = sp_search_artist(input(\"What artists would you like to see? \"))\n",
    "artist_search_df = sp_search_artist(\"A Fine Frenzy\")\n",
    "\n",
    "## Collect artist id and genres\n",
    "\n",
    "artist_search_id = list(artist_search_df.id)\n",
    "\n",
    "artist_search_genre = list(artist_search_df.genres)\n",
    "artist_search_genre = artist_search_genre[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starting to build album information, then saving off information for later calls\n",
    "\n",
    "album_search_df = sp_search_album(artist_search_id[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BEATLES ONLY\n",
    "\n",
    "# first_album_search = sp.album('3KzAvEXcqJKBF97HrXwlgf')\n",
    "\n",
    "# first_album_search_2 = first_album_search['tracks']\n",
    "# first_album_search_3 = first_album_search_2['items']\n",
    "# first_album_df = pd.DataFrame(first_album_search_3)\n",
    "\n",
    "# first_album_df['album_name'] = 'Please Please Me (Remastered)'\n",
    "# first_album_df['release_date'] = '1963-03-22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cutting off unwanted albums from Beatles\n",
    "\n",
    "# album_search_df = album_search_df.iloc[7:,:]\n",
    "\n",
    "album_search_df_2 = album_search_df[album_search_df.duplicated(subset = 'release_date', keep = 'last') == False]\n",
    "\n",
    "album_search_df_2.reset_index(drop = True, inplace = True)\n",
    "\n",
    "album_name_list = list(album_search_df.name)\n",
    "album_id = list(album_search_df.id)\n",
    "album_release_date = list(album_search_df.release_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iterating through albums to return a dataframe with track information\n",
    "\n",
    "for i in range(len(album_id)):\n",
    "    if i == 0:\n",
    "        album_track_df = sp_search_track(album_id[i], album_name_list[i], album_release_date[i])\n",
    "    else:\n",
    "        new_track_df = sp_search_track(album_id[i], album_name_list[i], album_release_date[i])\n",
    "        album_track_df = album_track_df.append(new_track_df)\n",
    "        album_track_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "#album_track_df = album_track_df[album_track_df.album_name != \"Sgt. Pepper's Lonely Hearts Club Band (Deluxe Edition)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BEATLES ONLY\n",
    "\n",
    "# album_track_df = pd.concat([first_album_df, album_track_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "#album_track_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Track list will be used to get audio_features and track_analysis for each song        \n",
    "        \n",
    "track_list = list(album_track_df.id)\n",
    "\n",
    "## Audio features for each song\n",
    "\n",
    "for i in range(len(track_list)):\n",
    "    if i == 0:\n",
    "        audio_features_df = sp_features_audio(track_list[i])\n",
    "    else:\n",
    "        new_audio_features_df = sp_features_audio(track_list[i])\n",
    "        audio_features_df = audio_features_df.append(new_audio_features_df)\n",
    "        audio_features_df.reset_index(drop = True, inplace = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Track analysis for each song\n",
    "\n",
    "track_analysis_df = audio_track_analysis(track_list)\n",
    "track_analysis_df.drop(columns = ['meta', 'track'], inplace = True)\n",
    "\n",
    "## Creating counts for each track_analysis record\n",
    "\n",
    "bars_count = count_stats(0, track_analysis_df)\n",
    "beats_count = count_stats(1, track_analysis_df)\n",
    "sections_count = count_stats(2, track_analysis_df)\n",
    "segments_count = count_stats(3, track_analysis_df)\n",
    "tatums_count = count_stats(4, track_analysis_df)\n",
    "\n",
    "audio_df = pd.DataFrame({'bars_count': bars_count, 'beats_count': beats_count, \n",
    "                      'sections_count': sections_count, 'segments_count': segments_count, \n",
    "                      'tatums_count': tatums_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "## Appending track id numbers to audio analysis\n",
    "\n",
    "track_series = pd.Series(track_list)\n",
    "\n",
    "audio_df = pd.concat([audio_df,track_series], axis = 1)\n",
    "audio_df = audio_df.rename(columns = {0 : 'id'})\n",
    "\n",
    "## Combining audio features and audio analysis features\n",
    "\n",
    "combined_df = pd.merge(album_track_df, audio_features_df, how = 'left', on = 'id')\n",
    "\n",
    "## Renaming columns in merged_df\n",
    "\n",
    "combined_df = combined_df[['href', 'id', 'name', 'track_number', 'album_name', 'release_date',\n",
    "    'acousticness', 'danceability', 'energy', 'instrumentalness', 'key', 'liveness', \n",
    "    'loudness', 'mode', 'speechiness', 'tempo', 'time_signature', 'valence']]\n",
    "\n",
    "audio_df = pd.concat([combined_df, audio_df], axis=1)\n",
    "\n",
    "## Creating a new field for song length (in seconds)\n",
    "\n",
    "song_length = []\n",
    "\n",
    "for i in range(len(album_track_df)):\n",
    "    song_seconds = (album_track_df['duration_ms'][i] / 1000)\n",
    "    song_length.append(song_seconds)\n",
    "\n",
    "## Calculating beats per minute and \n",
    "\n",
    "song_len = pd.Series(song_length)\n",
    "\n",
    "audio_analysis = pd.concat([audio_df, song_len], axis = 1)\n",
    "\n",
    "audio_analysis.rename(columns = {0 : 'song_length_seconds'}, inplace = True)\n",
    "\n",
    "audio_analysis['bpm'] = (audio_analysis['beats_count'] / (audio_analysis['song_length_seconds'] / 60))\n",
    "\n",
    "audio_analysis = audio_analysis.rename(columns = {'name' : 'song_name'})\n",
    "\n",
    "cols_to_use = combined_df.columns.difference(audio_analysis.columns)\n",
    "\n",
    "merged_df = pd.merge(audio_analysis, combined_df[cols_to_use], how = 'left', left_index=True, right_index=True)\n",
    "\n",
    "## Trimming down the audio features that I want to explore initially\n",
    "\n",
    "features_df = combined_df[['release_date', 'album_name', 'name', 'acousticness', 'danceability', 'energy', \n",
    "    'loudness', 'key', 'mode', 'tempo', 'valence']]\n",
    "\n",
    "## Separating the release date into year, month, day columns\n",
    "\n",
    "features_df['year'], features_df['month'], features_df['day'] = features_df['release_date'].str.split('-',2).str\n",
    "\n",
    "## Sort oldest album to newest album\n",
    "\n",
    "features_df = features_df.sort_values(by = ['year', 'month', 'day'])\n",
    "\n",
    "## Reset index and assign unique release dates to a list that will be used in the next loop\n",
    "\n",
    "features_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "unique_release = list(features_df.release_date.unique())\n",
    "\n",
    "## For loop that assigns an album number based on the release date for future plotting\n",
    "\n",
    "album_number = []\n",
    "\n",
    "count = 0\n",
    "record_number = 1\n",
    "\n",
    "for row in range(len(features_df)):\n",
    "    if features_df.release_date.iloc[row] == unique_release[count]:\n",
    "        #print(features_df.release_date.iloc[row], \"-------->\", unique_release[count], \"------->\", features_df.release_date.iloc[row] == unique_release[count])\n",
    "        album_number.append(record_number)\n",
    "    else:\n",
    "        #print('Change Album')\n",
    "        record_number += 1\n",
    "        count += 1\n",
    "        album_number.append(record_number)\n",
    "\n",
    "## Converting resulting list into a dataframe to concat, then renaming the column to show album_number\n",
    "\n",
    "album_number = pd.DataFrame(album_number)\n",
    "\n",
    "features_df = pd.concat([features_df, album_number], axis = 1)\n",
    "\n",
    "features_df.rename(columns = {0 : 'album_number', 'name' : 'song_name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A Fine Frenzy Only\n",
    "\n",
    "features_df = features_df[features_df.duplicated(subset = ['album_name', 'song_name'], keep = 'first') == False]\n",
    "\n",
    "features_df = features_df[features_df.duplicated(subset = ['release_date', 'song_name'], keep = 'first') == False]\n",
    "\n",
    "features_df = features_df.iloc[:-2,:]\n",
    "\n",
    "features_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Raw Dataframe for Linear Regression - Song Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use_2 = merged_df.columns.difference(features_df.columns)\n",
    "\n",
    "\n",
    "raw_features_df_2 = pd.merge(merged_df[cols_to_use_2], features_df, how = 'left', left_on='name', right_on='song_name')\n",
    "raw_features_df = pd.merge(merged_df[cols_to_use_2], features_df, how = 'left', left_on='name', right_on='song_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features_df_2 = raw_features_df_2[pd.notnull(raw_features_df_2.acousticness)]\n",
    "raw_features_df = raw_features_df[pd.notnull(raw_features_df.acousticness)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_features_df.to_csv('beatles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a melted dataframe for predicting future song features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rearranging columns\n",
    "\n",
    "melted_df = raw_features_df[['release_date',\n",
    "                            'album_number',\n",
    "                            'album_name',\n",
    "                            'track_number',\n",
    "                            'song_name',\n",
    "                            'year',\n",
    "                            'month',\n",
    "                            'day',\n",
    "                            'acousticness',\n",
    "                            'danceability',\n",
    "                            'energy',\n",
    "                            'loudness',\n",
    "                            'valence',\n",
    "                            'song_length_seconds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshaping dataframe to a long format\n",
    "\n",
    "melted_df = pd.melt(melted_df, \n",
    "                   id_vars = ['release_date',\n",
    "                            'album_number',\n",
    "                            'album_name',\n",
    "                            'track_number',\n",
    "                            'song_name',\n",
    "                            'year',\n",
    "                            'month',\n",
    "                            'day'], \n",
    "                   var_name = 'feature', value_name = 'value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing PCA on requested artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing data for plotting\n",
    "\n",
    "feature_col_names = ['acousticness',\n",
    "                     'danceability',\n",
    "                     'energy',\n",
    "                     'loudness',\n",
    "                     'bars_count',\n",
    "                     'beats_count',\n",
    "                     'sections_count',\n",
    "                     'segments_count',\n",
    "                     'tatums_count',\n",
    "                     'song_length_seconds',\n",
    "                     'bpm']\n",
    "\n",
    "## Iterating through columns to normalize the data \n",
    "\n",
    "for i in feature_col_names:\n",
    "    raw_features_df[i] = feature_norm(raw_features_df, i)\n",
    "\n",
    "## Reducing features\n",
    "\n",
    "pca_df = raw_features_df[['album_number',\n",
    "                     'acousticness',\n",
    "                     'danceability',\n",
    "                     'energy',\n",
    "                     'bars_count',\n",
    "                     'sections_count',\n",
    "                     'segments_count',\n",
    "                     'tatums_count',\n",
    "                     'song_length_seconds',\n",
    "                     'bpm']]\n",
    "\n",
    "## Splitting data into target and features\n",
    "\n",
    "y = pca_df['album_number']\n",
    "X_norm = pca_df.iloc[:,1:]\n",
    "\n",
    "## Requesting to use n_compenents that accounts for 95% of variance and applying fit_transform to the model\n",
    "\n",
    "pca = sklearnPCA(n_components = .95)\n",
    "transformed = pd.DataFrame(pca.fit_transform(X_norm))\n",
    "\n",
    "## Print statements to show the impact of each feature\n",
    "\n",
    "pca_len = len(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27292204 0.17060973 0.04507612 0.03773001]\n",
      "   acousticness  danceability    energy  bars_count  sections_count  \\\n",
      "0      0.590668     -0.304043 -0.507511   -0.240850       -0.181266   \n",
      "1      0.387361     -0.282862 -0.251678    0.411712        0.331008   \n",
      "2     -0.151056     -0.730952  0.237901    0.119366       -0.266891   \n",
      "3      0.324615      0.507827 -0.121439    0.093655       -0.112743   \n",
      "\n",
      "   segments_count  tatums_count  song_length_seconds       bpm  \n",
      "0       -0.258264     -0.262442            -0.208998 -0.176010  \n",
      "1        0.328595      0.384826             0.408244  0.069262  \n",
      "2       -0.191736      0.124634            -0.163504  0.470941  \n",
      "3       -0.074370      0.111176            -0.203789  0.735586  \n"
     ]
    }
   ],
   "source": [
    "## Print statements to show the impact of each feature\n",
    "\n",
    "print(pca.explained_variance_)\n",
    "\n",
    "print(pd.DataFrame(pca.components_,columns=X_norm.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis - Requested Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1774,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining 4 components for LDA and applying fit_transform\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components = pca_len)\n",
    "transformed_lda = pd.DataFrame(lda.fit_transform(X_norm, y))\n",
    "\n",
    "## Defining 4 components for LDA and applying fit_transform\n",
    "\n",
    "tsne_req = TSNE(n_components = 2, perplexity = 60, learning_rate = 900, n_iter = 1000)\n",
    "transformed_tsne = pd.DataFrame(tsne_req.fit_transform(transformed_lda))\n",
    "\n",
    "## Creating new df for interactive Bokeh graphs\n",
    "\n",
    "tsne_df = pd.concat([raw_features_df[['album_name', 'song_name', 'album_number']], transformed_tsne.iloc[:,:2]], axis=1, join_axes=[raw_features_df.index])\n",
    "\n",
    "tsne_df.rename(columns = {0 : 'x', 1 : 'y'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1775,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = tsne_df[tsne_df.duplicated(subset = ['album_name', 'song_name'], keep = 'first') == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1776,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Beatles Only\n",
    "\n",
    "#color_palette = ['#212F3C', '#515A5A', '#873600', '#979A9A', '#186A3B', '#117A65', \n",
    "#                 '#17A589', '#2874A6', '#5B2C6F', '#884EA0', '#78281F', '#A93226', '#CB4335', '#141414']\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1777,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Beatles Only\n",
    "\n",
    "#album_name_list = ['Please Please Me (Remastered)', 'With The Beatles (Remastered)', \"A Hard Day's Night (Remastered)\",\n",
    "#                        'Beatles For Sale (Remastered)', 'Help! (Remastered)', 'Rubber Soul (Remastered)', 'Revolver (Remastered)',\n",
    "#                        \"Sgt. Pepper's Lonely Hearts Club Band (Remastered)\", 'Magical Mystery Tour (Remastered)',\n",
    "#                        'The Beatles (Remastered)', 'Yellow Submarine (Remastered)', 'Abbey Road (Remastered)', 'Let It Be (Remastered)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1778,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AFF Only\n",
    "\n",
    "# album_name_list = ['PINES', 'Bomb In A Birdcage', 'One Cell In The Sea']\n",
    "\n",
    "# palette_1 = palette[11]\n",
    "\n",
    "# palette_2 = ['#000000', '#525b91', '#4e6b4e']\n",
    "\n",
    "# tsne_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\n",
    "# for i in range(len(tsne_df)):\n",
    "#     if tsne_df.album_name[i] == 'PINES':\n",
    "#         tsne_df.album_number[i] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE Plot - Requested Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1781,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resetting the html output to prevent multiple graphs from showing up\n",
    "\n",
    "bpl.reset_output()\n",
    "\n",
    "## Hover tool set to show album number, album name and song name\n",
    "\n",
    "hover = bmo.HoverTool(\n",
    "    tooltips = [\n",
    "        ('Album #: ', '@album_number'),\n",
    "        ('Album Name: ', '@album_name'),\n",
    "        ('Song Name: ', '@song_name')])\n",
    "\n",
    "## Configuring tools that will be used in the plot (plot size is large for viewing on monitor and not laptop)\n",
    "\n",
    "p = figure(tools = [hover, \"box_select, box_zoom, lasso_select, reset\"], plot_width = 1200, plot_height = 800,  toolbar_location = 'above')\n",
    "\n",
    "## Removing all lines and text, since location on the grid doesn't add any information for analysis\n",
    "\n",
    "p.xaxis.major_tick_line_color = None\n",
    "p.xaxis.minor_tick_line_color = None\n",
    "p.xaxis.axis_line_color = None\n",
    "p.xaxis.major_label_text_font_size = '0pt'\n",
    "\n",
    "p.yaxis.major_tick_line_color = None\n",
    "p.yaxis.minor_tick_line_color = None\n",
    "p.yaxis.axis_line_color = None\n",
    "p.yaxis.major_label_text_font_size = '0pt'\n",
    "\n",
    "p.grid.visible = False\n",
    "\n",
    "## Creating color palette/map\n",
    "\n",
    "#palette = d3['Category20c']\n",
    "color_map = bmo.CategoricalColorMapper(factors = tsne_df['album_name'].unique(), palette = palette_2) \n",
    "\n",
    "p.background_fill_color = '#F8F9FB'\n",
    "p.background_fill_alpha = 0.0\n",
    "p.outline_line_alpha = 0.0\n",
    "\n",
    "## Creating plots and legend information\n",
    "\n",
    "plot_names = []\n",
    "legend_list = []\n",
    "\n",
    "for i in range(len(album_name_list)):\n",
    "    plot_names.append(\"tsne_plot_\" + str(i))\n",
    "     \n",
    "for j in range(len(plot_names)):\n",
    "    plot_names[j] = p.circle(x = 'x', y = 'y', source = tsne_df[tsne_df.album_name == album_name_list[j]], color = palette_2[j], \n",
    "                        size = 6, alpha = 0.95, muted_color = palette_2[j], muted_alpha = 0.1)\n",
    "    legend_list.append((album_name_list[j], [plot_names[j]]))\n",
    "    \n",
    "legend = Legend(items = legend_list, location = (0,30))\n",
    "\n",
    "p.add_layout(legend, 'right')\n",
    "p.legend.click_policy = 'mute'\n",
    "p.legend.border_line_alpha = 0.0\n",
    "p.legend.background_fill_alpha = 0.0\n",
    "p.legend.label_text_color = \"black\"\n",
    "p.border_fill_alpha = 0.0\n",
    "\n",
    "## Show the Results\n",
    "\n",
    "#output_file(\"Arctic_Monkeys_TSNE_plot.html\")\n",
    "#bpl.output_notebook()\n",
    "show(p)\n",
    "\n",
    "#script, div = components(plot)\n",
    "js, tag = bem.autoload_static(p, CDN, \"/Users/justin/Code/A Fine Frenzy Webpage/Squadfree/aff_scripts/ff_script.js\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1785,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1786,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting future album features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a key:value dictionary pair from the unique features\n",
    "## This will be used by spotify to recommend similar songs to our predicted values\n",
    "\n",
    "keys = []\n",
    "values = []\n",
    "\n",
    "unique_feat_list = list(melted_df.feature.unique())\n",
    "\n",
    "for i in unique_feat_list:\n",
    "    keys.append(i)\n",
    "    values.append(future_value(melted_df, i))\n",
    "\n",
    "pred_dicts = dict(zip(keys, values))\n",
    "\n",
    "## Spotify asks for the recommended song length in ms\n",
    "\n",
    "pred_dicts['song_length_seconds'] = round(pred_dicts['song_length_seconds']*1000)\n",
    "\n",
    "## Uses the artist seed and predicted values to return songs that are similiar\n",
    "\n",
    "results = sp.recommendations(seed_artists = artist_search_id, limit = 10, min_popularity = 70,\n",
    "                                     target_acousticness = pred_dicts['acousticness'],\n",
    "                                     target_danceability = pred_dicts['danceability'],\n",
    "                                     target_energy = pred_dicts['energy'],\n",
    "                                     target_loudness = pred_dicts['loudness'],\n",
    "                                     target_target_duration_ms = pred_dicts['song_length_seconds'],\n",
    "                                     target_valence = pred_dicts['valence'])\n",
    "\n",
    "## Unpack values and create a dataframe\n",
    "\n",
    "results = results['tracks']\n",
    "\n",
    "recommend_df = pd.DataFrame(results)\n",
    "\n",
    "## Taking the track ID for additional analysis, plus the song popularity to incorporate popular areas to move into\n",
    "\n",
    "recommended_tracks = []\n",
    "popularity = []\n",
    "\n",
    "for i in range(len(recommend_df)):\n",
    "    recommended_tracks.append(recommend_df.uri[i])\n",
    "    popularity.append(recommend_df.popularity[i])\n",
    "\n",
    "## Call function and store audio features from recommended songs into a dataframe\n",
    "\n",
    "recommend_audio_feat = sp_features_audio(recommended_tracks)\n",
    "\n",
    "## Call function and store audio track features from recommended songs into a dataframe\n",
    "\n",
    "recommend_track_analysis = audio_track_analysis(recommended_tracks)\n",
    "\n",
    "## Creating counts for each track_analysis record\n",
    "\n",
    "bars_count_rec = count_stats(0, recommend_track_analysis)\n",
    "beats_count_rec = count_stats(1, recommend_track_analysis)\n",
    "sections_count_rec = count_stats(2, recommend_track_analysis)\n",
    "segments_count_rec = count_stats(3, recommend_track_analysis)\n",
    "tatums_count_rec = count_stats(4, recommend_track_analysis)\n",
    "\n",
    "audio_df_recommend = pd.DataFrame({'bars_count': bars_count, 'beats_count': beats_count, \n",
    "                      'sections_count': sections_count, 'segments_count': segments_count, \n",
    "                      'tatums_count': tatums_count})\n",
    "\n",
    "\n",
    "## Calculating beats per minute and \n",
    "\n",
    "#song_len_rec = pd.Series(song_length_rec)\n",
    "\n",
    "song_len_rec = recommend_audio_feat['duration_ms']\n",
    "\n",
    "song_len_rec = song_len_rec.rename('song_length_seconds')\n",
    "\n",
    "audio_analysis_rec = pd.concat([audio_df_recommend, song_len_rec], axis = 1)\n",
    "\n",
    "\n",
    "# audio_analysis_rec = recommend_audio_feat\n",
    "\n",
    "audio_analysis_rec['bpm'] = (audio_analysis_rec['beats_count'] / (audio_analysis_rec['song_length_seconds'] / 60))\n",
    "\n",
    "## Merge track analysis and audio features, then append an album \n",
    "\n",
    "raw_df_recommend = pd.merge(recommend_audio_feat, audio_analysis_rec, how = 'left', left_index = True, right_index = True)\n",
    "raw_df_recommend['album_number'] = len(raw_features_df.album_number.unique()) + 1\n",
    "\n",
    "raw_df_recommend['spotify_link'] = 'https://embed.spotify.com/?uri=spotify:track:' + raw_df_recommend.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popular Albums in the Same Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1798,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uses the artist seed and predicted values to return songs that are similiar\n",
    "\n",
    "results = sp.recommendations(seed_artists = artist_search_id, limit = 10, min_popularity = 55,\n",
    "                                     target_acousticness = pred_dicts['acousticness'],\n",
    "                                     target_danceability = pred_dicts['danceability'],\n",
    "                                     target_energy = pred_dicts['energy'],\n",
    "                                     target_loudness = pred_dicts['loudness'],\n",
    "                                     target_target_duration_ms = pred_dicts['song_length_seconds'],\n",
    "                                     target_valence = pred_dicts['valence'])\n",
    "\n",
    "## Unpack values and create a dataframe\n",
    "\n",
    "results = results['tracks']\n",
    "\n",
    "recommend_df = pd.DataFrame(results)\n",
    "\n",
    "## Taking the track ID for additional analysis, plus the song popularity to incorporate popular areas to move into\n",
    "\n",
    "recommended_tracks = []\n",
    "popularity = []\n",
    "\n",
    "for i in range(len(recommend_df)):\n",
    "    recommended_tracks.append(recommend_df.uri[i])\n",
    "    popularity.append(recommend_df.popularity[i])\n",
    "  \n",
    "\n",
    "  \n",
    "## Creating a popularity Series for plotting\n",
    "\n",
    "popularity_series = pd.Series(popularity)\n",
    "popularity_series = popularity_series.rename(\"popularity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1800,
   "metadata": {},
   "outputs": [],
   "source": [
    "##AFF Only\n",
    "\n",
    "# for i in range(len(recommend_df)):\n",
    "#     print(\"https://open.spotify.com/track/\" + recommend_df.id[i])\n",
    "\n",
    "# recommended_tracks = recommended_tracks[1:]\n",
    "\n",
    "# recommended_tracks.remove( 'spotify:track:71ehTADpxs85ULrZgSEKCy')\n",
    "\n",
    "# recommended_tracks\n",
    "\n",
    "# recommend_df = recommend_df.iloc[1:,]\n",
    "\n",
    "# recommend_df = recommend_df.drop([6], axis = 0)\n",
    "\n",
    "# recommend_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling data for recommendations for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1862,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Audio features for each song\n",
    "\n",
    "for i in range(len(recommended_tracks)):\n",
    "    if i == 0:\n",
    "        rec_audio_features_df = sp_features_audio(recommended_tracks[i])\n",
    "    else:\n",
    "        rec_new_audio_features_df = sp_features_audio(recommended_tracks[i])\n",
    "        rec_audio_features_df = rec_audio_features_df.append(rec_new_audio_features_df)\n",
    "        rec_audio_features_df.reset_index(drop = True, inplace = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1863,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Track analysis for each song\n",
    "\n",
    "rec_track_analysis_df = audio_track_analysis(recommended_tracks)\n",
    "rec_track_analysis_df.drop(columns = ['meta', 'track'], inplace = True)\n",
    "\n",
    "## Creating counts for each track_analysis record\n",
    "\n",
    "bars_count = count_stats(0, rec_track_analysis_df)\n",
    "beats_count = count_stats(1, rec_track_analysis_df)\n",
    "sections_count = count_stats(2, rec_track_analysis_df)\n",
    "segments_count = count_stats(3, rec_track_analysis_df)\n",
    "tatums_count = count_stats(4, rec_track_analysis_df)\n",
    "\n",
    "rec_audio_df = pd.DataFrame({'bars_count': bars_count, 'beats_count': beats_count, \n",
    "                      'sections_count': sections_count, 'segments_count': segments_count, \n",
    "                      'tatums_count': tatums_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1864,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combining audio features and audio analysis features\n",
    "\n",
    "rec_combined_df = pd.merge(rec_audio_df, rec_audio_features_df, how = 'left', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1865,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calulating song length seconds\n",
    "\n",
    "rec_combined_df['song_length_seconds'] = (rec_combined_df['duration_ms'] / 1000) \n",
    "\n",
    "## Calculating beats per minute\n",
    "\n",
    "rec_combined_df['bpm'] = (rec_combined_df['beats_count'] / (rec_combined_df['song_length_seconds'] / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1866,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_combined_df_2 = rec_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1867,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pulling song titles for recommended titles\n",
    "\n",
    "rec_song_titles = sp_track_info(recommended_tracks)\n",
    "\n",
    "rec_song_titles = rec_song_titles['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing - Recommended Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1868,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing data for plotting\n",
    "\n",
    "rec_feature_col_names = ['acousticness',\n",
    "                     'danceability',\n",
    "                     'energy',\n",
    "                     'loudness',\n",
    "                     'bars_count',\n",
    "                     'beats_count',\n",
    "                     'sections_count',\n",
    "                     'segments_count',\n",
    "                     'tatums_count',\n",
    "                     'song_length_seconds',\n",
    "                     'bpm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1869,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing data for plotting\n",
    "\n",
    "feature_col_names = ['acousticness',\n",
    "                     'danceability',\n",
    "                     'energy',\n",
    "                     'loudness',\n",
    "                     'bars_count',\n",
    "                     'beats_count',\n",
    "                     'sections_count',\n",
    "                     'segments_count',\n",
    "                     'tatums_count',\n",
    "                     'song_length_seconds',\n",
    "                     'bpm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1870,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_combined_df = pd.concat([rec_combined_df, rec_song_titles], axis = 1)\n",
    "\n",
    "rec_combined_df = rec_combined_df.rename(columns = {'name': 'song_name'})\n",
    "\n",
    "## Adding \"album_number\" to match what I used in the original fitting\n",
    "rec_combined_df['album_number'] = len(raw_features_df_2.album_number.unique()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1871,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['id'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1871-e6ecba523cd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_features_df_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3744\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['id'] not contained in axis"
     ]
    }
   ],
   "source": [
    "raw_features_df_2.drop(columns = ['id'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1872,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_normalization = pd.concat([rec_combined_df,raw_features_df_2], axis = 0)\n",
    "\n",
    "## Removing duplicates that may have come from the recommendations\n",
    "\n",
    "combined_normalization = combined_normalization[combined_normalization.duplicated(subset = 'song_name', keep = 'last') == False]\n",
    "combined_normalization.reset_index(drop = True, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1873,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_song_list_unique = combined_normalization[pd.isnull(combined_normalization.album_name)]\n",
    "\n",
    "rec_song_list_unique = rec_song_list_unique['song_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1874,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing data for plotting\n",
    "\n",
    "feature_col_names = ['acousticness',\n",
    "                     'danceability',\n",
    "                     'energy',\n",
    "                     'loudness',\n",
    "                     'bars_count',\n",
    "                     'beats_count',\n",
    "                     'sections_count',\n",
    "                     'segments_count',\n",
    "                     'tatums_count',\n",
    "                     'song_length_seconds',\n",
    "                     'bpm']\n",
    "\n",
    "## Iterating through columns to normalize the data \n",
    "\n",
    "for i in feature_col_names:\n",
    "    combined_normalization[i] = feature_norm(combined_normalization, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1875,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_normalization = combined_normalization.sort_values(by = ['album_number', 'track_number'], ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA - Recommended tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1876,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reducing features\n",
    "\n",
    "rec_pca_df = combined_normalization[[\n",
    "                     'album_number',\n",
    "                     'acousticness',\n",
    "                     'danceability',\n",
    "                     'energy',\n",
    "                     'bars_count',\n",
    "                     'sections_count',\n",
    "                     'segments_count',\n",
    "                     'tatums_count',\n",
    "                     'song_length_seconds',\n",
    "                     'bpm']]\n",
    "\n",
    "\n",
    "## Splitting data into target and features\n",
    "\n",
    "rec_y = rec_pca_df['album_number']\n",
    "rec_X_norm = rec_pca_df.iloc[:,1:]\n",
    "\n",
    "## Transforming using previously-fit PCA model\n",
    "\n",
    "rec_transformed = pd.DataFrame(pca.transform(rec_X_norm))\n",
    "\n",
    "## Print statements to show the impact of each feature\n",
    "\n",
    "pca_len = len(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA & TSNE - Recommended Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1877,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transforming using previously-fit LDA model\n",
    "\n",
    "rec_transformed_lda = pd.DataFrame(lda.transform(rec_X_norm))\n",
    "\n",
    "## Defining 4 components for LDA and applying fit_transform\n",
    "\n",
    "tsne_req = TSNE(n_components = 2, perplexity = 60, learning_rate = 900, n_iter = 1000)\n",
    "\n",
    "rec_transformed_tsne = pd.DataFrame(tsne.fit_transform(rec_transformed_lda))\n",
    "\n",
    "## Creating new df for interactive Bokeh graphs\n",
    "\n",
    "rec_tsne_df = pd.concat([rec_transformed_tsne.iloc[:,:2]], axis=1, join_axes=[rec_combined_df.index])\n",
    "\n",
    "rec_tsne_df.rename(columns = {0 : 'x', 1 : 'y'}, inplace = True)\n",
    "\n",
    "# ## Appending popularity\n",
    "\n",
    "# rec_tsne_df = pd.concat([rec_tsne_df, popularity_series], axis = 1)\n",
    "\n",
    "## Appending song name\n",
    "\n",
    "rec_tsne_df = pd.concat([rec_tsne_df, rec_song_list_unique], axis = 1)\n",
    "\n",
    "## Creating album name for recommended songs\n",
    "\n",
    "rec_tsne_df['album_name'] = 'Recommended Popular Song'\n",
    "\n",
    "# Creating album name for recommended songs\n",
    "\n",
    "rec_tsne_df['album_number'] = 'None'\n",
    "\n",
    "rec_tsne_df = rec_tsne_df[pd.notnull(rec_tsne_df.song_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1878,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:3027: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "## Pulling out the original tracks - now normalized again\n",
    "\n",
    "original_tracks_tojoin = rec_transformed_tsne.iloc[len(rec_tsne_df):,]\n",
    "\n",
    "original_tracks_tojoin.reset_index(drop = True, inplace = True)\n",
    "\n",
    "original_tracks_tojoin.rename(columns = {0 : 'x', 1 : 'y'}, inplace = True)\n",
    "\n",
    "original_tracks_tsne_df = pd.concat([original_tracks_tojoin, raw_features_df_2[['song_name', 'album_name', 'album_number']]], axis=1, join_axes=[raw_features_df_2.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1879,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_tsne_df = original_tracks_tsne_df.append(rec_tsne_df)\n",
    "\n",
    "overlay_album_list = list(overlay_tsne_df.album_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1880,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_tsne_df = overlay_tsne_df[overlay_tsne_df.duplicated(subset = ['album_name', 'song_name'], keep = 'first') == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1881,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "overlay_tsne_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "for i in range(len(tsne_df)):\n",
    "    if tsne_df.album_name[i] == 'PINES':\n",
    "        tsne_df.album_number[i] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1882,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay_album_list  = ['Please Please Me (Remastered)', 'With The Beatles (Remastered)', \"A Hard Day's Night (Remastered)\",\n",
    "#                        'Beatles For Sale (Remastered)', 'Help! (Remastered)', 'Rubber Soul (Remastered)', 'Revolver (Remastered)',\n",
    "#                        \"Sgt. Pepper's Lonely Hearts Club Band (Remastered)\", 'Magical Mystery Tour (Remastered)',\n",
    "#                        'The Beatles (Remastered)', 'Yellow Submarine (Remastered)', 'Abbey Road (Remastered)', \n",
    "#                        'Let It Be (Remastered)', 'Recommended Popular Song']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1883,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AFF Only\n",
    "\n",
    "# palette_2 = ['#000000', '#525b91', '#4e6b4e']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting TSNE with Recommended Tracks overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1884,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resetting the html output to prevent multiple graphs from showing up\n",
    "\n",
    "bpl.reset_output()\n",
    "\n",
    "## Hover tool set to show album number, album name and song name\n",
    "\n",
    "hover = bmo.HoverTool(\n",
    "    tooltips = [\n",
    "        ('Album #: ', '@album_number'),\n",
    "        ('Album Name: ', '@album_name'),\n",
    "        ('Song Name: ', '@song_name')])\n",
    "\n",
    "## Configuring tools that will be used in the plot (plot size is large for viewing on monitor and not laptop)\n",
    "\n",
    "p = figure(tools = [hover, \"box_select, box_zoom, lasso_select, reset\"], plot_width = 1200, plot_height = 800,  toolbar_location = 'above')\n",
    "\n",
    "## Removing all lines and text, since location on the grid doesn't add any information for analysis\n",
    "\n",
    "p.xaxis.major_tick_line_color = None\n",
    "p.xaxis.minor_tick_line_color = None\n",
    "p.xaxis.axis_line_color = None\n",
    "p.xaxis.major_label_text_font_size = '0pt'\n",
    "\n",
    "p.yaxis.major_tick_line_color = None\n",
    "p.yaxis.minor_tick_line_color = None\n",
    "p.yaxis.axis_line_color = None\n",
    "p.yaxis.major_label_text_font_size = '0pt'\n",
    "\n",
    "p.grid.visible = False\n",
    "\n",
    "## Creating color palette/map\n",
    "palette_3 = ['#bc1818']\n",
    "# palette_3 = ['#1E1E1E']\n",
    "# palette = d3['Category20c'][len(overlay_tsne_df['album_name'].unique())-1]\n",
    "# palette = palette\n",
    "palette_2.extend(palette_3)\n",
    "color_map = bmo.CategoricalColorMapper(factors = overlay_tsne_df['album_name'].unique(), palette = palette_2) \n",
    "\n",
    "p.background_fill_color = '#F8F9FB'\n",
    "p.background_fill_alpha = 0.0\n",
    "p.outline_line_alpha = 0.0\n",
    "\n",
    "## Creating plots and legend information\n",
    "\n",
    "plot_names = []\n",
    "legend_list = []\n",
    "\n",
    "for i in range(len(overlay_album_list)):\n",
    "    plot_names.append(\"tsne_plot_\" + str(i))\n",
    "     \n",
    "for j in range(len(plot_names)):\n",
    "    plot_names[j] = p.circle(x = 'x', y = 'y', source = overlay_tsne_df[overlay_tsne_df.album_name == overlay_album_list[j]], color = palette_2[j], \n",
    "                        size = 6, alpha = 0.75, muted_color = palette_2[j], muted_alpha = 0.1)\n",
    "    legend_list.append((overlay_album_list[j], [plot_names[j]]))\n",
    "    \n",
    "legend = Legend(items = legend_list, location = (0,30))\n",
    "\n",
    "p.add_layout(legend, 'right')\n",
    "p.legend.click_policy = 'mute'\n",
    "p.legend.border_line_alpha = 0.0\n",
    "p.legend.background_fill_alpha = 0.0\n",
    "p.legend.label_text_color = \"black\"\n",
    "p.border_fill_alpha = 0.0\n",
    "\n",
    "## Show the Results\n",
    "\n",
    "# output_file(\"Arctic_Monkeys_song_TSNE_plot.html\")\n",
    "# bpl.output_notebook()\n",
    "show(p)\n",
    "\n",
    "#script, div = components(plot)\n",
    "js, tag = bem.autoload_static(p, CDN, \"/Users/justin/Code/A Fine Frenzy Webpage/Squadfree/aff_scripts/aff_rec_script.js\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1910,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1911,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating album feature plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1887,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating means for each of the original albums\n",
    "\n",
    "combined_norm_melt_df = combined_normalization[['album_number', 'album_name',\n",
    "        'bars_count', 'danceability', 'energy', 'acousticness']]\n",
    "\n",
    "original_album_means = combined_norm_melt_df.groupby(['album_number', 'album_name']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1888,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_album_means = original_album_means[original_album_means.duplicated(subset = 'album_name', keep = 'first') == False]\n",
    "original_album_means.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1890,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renaming with weird spacing for plotting purposes\n",
    "\n",
    "original_album_means = original_album_means.rename(columns = {'album_name' : 'Album Name',\n",
    "                                                              'acousticness' : 'Acousticness', \n",
    "                                                              'danceability' : 'Danceability', \n",
    "                                                              'energy' : 'Energy         ', \n",
    "                                                              'bars_count' : '                Bars Count   ', \n",
    "                                                              #'sections_count' : '                         Sections Count'\n",
    "                                                             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1891,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating means for each of the recommended tracks\n",
    "\n",
    "rec_song_means = combined_norm_melt_df[pd.isnull(combined_norm_melt_df.album_name)]\n",
    "\n",
    "rec_song_means = rec_song_means.drop(columns = ['album_number', 'album_name'])\n",
    "\n",
    "rec_song_means = pd.concat([rec_song_means, rec_song_list_unique], axis=1, join_axes=[rec_song_titles.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1892,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_song_means = rec_song_means[pd.notnull(rec_song_means.song_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1893,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_song_means = rec_song_means.groupby(['song_name']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1902,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renaming with weird spacing for plotting purposes\n",
    "\n",
    "rec_song_means = rec_song_means.rename(columns = {'song_name' : 'Song Name',\n",
    "                                                              'acousticness' : 'Acousticness', \n",
    "                                                              'danceability' : 'Danceability', \n",
    "                                                              'energy' : 'Energy         ', \n",
    "                                                              'bars_count' : '                Bars Count   ', \n",
    "                                                              #'sections_count' : '                         Sections Count'\n",
    "                                                             })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1903,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_song_means = rec_song_means[pd.notnull(rec_song_means.iloc[:,1])]\n",
    "\n",
    "rec_song_means.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1904,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_album_means.to_csv('original_album_means.csv', index = False)\n",
    "#original_album_means = pd.read_csv('original_album_means.csv')\n",
    "\n",
    "rec_song_means.to_csv('rec_song_means.csv', index = False)\n",
    "#rec_song_means = pd.read_csv('rec_song_means.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating radar plots using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1905,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_radar (df, col):\n",
    "    \n",
    "    ## Create list of 'categories' for chart\n",
    "\n",
    "    categories = list(df)[2:]\n",
    "    cat_len = len(categories)\n",
    "\n",
    "    ## Flatten df to plot the first record\n",
    "\n",
    "    plot_vals = df.loc[col].drop(['album_number', 'Album Name']).values.flatten().tolist()\n",
    "\n",
    "    plot_vals += plot_vals[:1]\n",
    "\n",
    "    plot_vals \n",
    "\n",
    "    ## Calculating angle for plot (code found online - math stuff...)\n",
    "\n",
    "    angles = [n / float(cat_len) * 2 * pi for n in range(cat_len)]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    ## Creating the plot - single plot\n",
    "\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "\n",
    "    plt.xticks(angles[:-1], categories, color='grey', size=15)\n",
    "\n",
    "    ## Not displaying values, since all values are normalized and doesn't enhance user experience\n",
    "\n",
    "    plt.yticks([0,0.5,1.0], [\"\"], color=\"grey\", size=10)\n",
    "\n",
    "    ## All normalized values are between 0 and 1\n",
    "    plt.ylim(0,1.0)\n",
    "    \n",
    "    # Plot data\n",
    "    ax.plot(angles, plot_vals, linewidth=2, linestyle='solid', color = '#92b597')\n",
    "\n",
    "    # Fill area\n",
    "    ax.fill(angles, plot_vals, '#92b597', alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1906,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a14396208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Creating and saving a radar chart for each album, then exporting results\n",
    "\n",
    "original_radar_names = []\n",
    "\n",
    "for i in range(len(original_album_means)):\n",
    "    radar_name = original_album_means['Album Name'][i]\n",
    "    original_radar_names.append(radar_name)\n",
    "    original_radar_names[i] = create_radar(original_album_means, i)\n",
    "    save_location = 'radar_charts/' + radar_name + '.png'\n",
    "    plt.savefig(save_location, dpi = 800, transparent = True)\n",
    "    plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1907,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rec_radar (df, col):\n",
    "    \n",
    "    ## Create list of 'categories' for chart\n",
    "\n",
    "    categories = list(df)[1:]\n",
    "    cat_len = len(categories)\n",
    "\n",
    "    ## Flatten df to plot the first record\n",
    "\n",
    "    plot_vals = df.loc[col].drop(['Song Name']).values.flatten().tolist()\n",
    "\n",
    "    plot_vals += plot_vals[:1]\n",
    "\n",
    "    plot_vals\n",
    "\n",
    "    ## Calculating angle for plot (code found online - math stuff...)\n",
    "\n",
    "    angles = [n / float(cat_len) * 2 * pi for n in range(cat_len)]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    ## Creating the plot - single plot\n",
    "\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "\n",
    "    plt.xticks(angles[:-1], categories, color='grey', size=15)\n",
    "\n",
    "    ## Not displaying values, since all values are normalized and doesn't enhance user experience\n",
    "\n",
    "    plt.yticks([0,0.5,1.0], [\"\"], color=\"grey\", size=10)\n",
    "\n",
    "    ## All normalized values are between 0 and 1\n",
    "    plt.ylim(0,1.0)\n",
    "\n",
    "    # Plot data\n",
    "    ax.plot(angles, plot_vals, linewidth=1, linestyle='solid', color = 'r')\n",
    "\n",
    "    # Fill area\n",
    "    ax.fill(angles, plot_vals, 'r', alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1909,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2b770c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Creating and saving a radar chart for each album, then exporting results\n",
    "\n",
    "rec_radar_names = []\n",
    "\n",
    "for i in range(len(rec_song_means)):\n",
    "    radar_names = rec_song_means['Song Name'][i] + \"_Recommended\"\n",
    "    rec_radar_names.append(radar_names)\n",
    "    rec_radar_names[i] = create_rec_radar(rec_song_means, i)\n",
    "    save_location = 'radar_charts/' + radar_names + '.png'\n",
    "    plt.savefig(save_location, dpi = 800, transparent = True)\n",
    "    plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap Work Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411.3618731498718\n"
     ]
    }
   ],
   "source": [
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
