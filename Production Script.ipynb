{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Basic Packages\n",
    "\n",
    "import time\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "## Sklearn packages\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "## Spotipy packages (Spotify API)\n",
    "\n",
    "import spotipy.oauth2\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import spotipy.util as util\n",
    "import spotipy\n",
    "\n",
    "## Importing Bokeh to explore outliers\n",
    "\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "import bokeh.models as bmo\n",
    "from bokeh.palettes import d3\n",
    "from bokeh.models import Legend, BoxSelectTool, BoxZoomTool, LassoSelectTool\n",
    "import bokeh.plotting as bpl\n",
    "\n",
    "## Notebook display settings\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "## Audio feature descriptions\n",
    "\n",
    "#https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "            User authentication requires interaction with your\n",
      "            web browser. Once you enter your credentials and\n",
      "            give authorization, you will be redirected to\n",
      "            a url.  Paste that url you were directed to to\n",
      "            complete the authorization.\n",
      "\n",
      "        \n",
      "Opened https://accounts.spotify.com/authorize?client_id=c11d185f127941938988ee6a37061b85&response_type=code&redirect_uri=http%3A%2F%2Flocalhost%3A8777%2Fcallback%2F in your browser\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "token = util.prompt_for_user_token(username = sp_username, client_id= sp_client_id,client_secret= sp_client_secret,redirect_uri=sp_redirect_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spotipy.Spotify(auth=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions Related to API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_search_artist(sp_artist_name):\n",
    "        ## Takes user name from user input and searches for artist information - returns dataframe\n",
    "        artist_search_results = sp.search(q = sp_artist_name, limit = 1, type = 'artist')\n",
    "        artist_search_results_2 = artist_search_results['artists']\n",
    "        artist_search_results_3 = artist_search_results_2['items']\n",
    "        sp_search_artists_df = pd.DataFrame(artist_search_results_3)\n",
    "        return sp_search_artists_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_search_track(sp_track_id):\n",
    "        ## Takes user name from user input and searches for artist information - returns dataframe\n",
    "        track_search_results = sp.search(q = sp_track_id, limit = 10, type = 'track')\n",
    "        track_search_results_2 = track_search_results['track']\n",
    "        track_search_results_3 = track_search_results_2['items']\n",
    "        sp_search_track_df = pd.DataFrame(track_search_results_3)\n",
    "        return sp_search_track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_search_album(sp_artist_id):\n",
    "        ## Search for albums based on artist ID\n",
    "        album_search_results = sp.artist_albums(sp_artist_id, album_type = 'album')\n",
    "        album_search_results_2 = album_search_results['items']\n",
    "        sp_search_album_df = pd.DataFrame(album_search_results_2)       \n",
    "        return sp_search_album_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_search_track(album, alb_num, rel_date):\n",
    "        ## Function that utilizes Spotify's album_tracks method to return all tracks from an album ID\n",
    "        track_search_results = sp.album_tracks(album, limit = 50)\n",
    "        track_search_results_2 = track_search_results['items']\n",
    "        sp_search_track_df = pd.DataFrame(track_search_results_2)\n",
    "        sp_search_track_df['album_name'] = alb_num\n",
    "        sp_search_track_df['release_date'] = rel_date\n",
    "        return sp_search_track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_features_audio(song_list):\n",
    "        ## Function that utilizes Spotify's audio_features method to return audio features (energy, tempo, etc)\n",
    "        audio_features_results = sp.audio_features(tracks = song_list)\n",
    "        audio_df = pd.DataFrame(audio_features_results)\n",
    "        return audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_track_analysis(song_list):\n",
    "        ## Function that utilizes Spotify's audio_features method to return audio features (energy, tempo, speechiness, etc)\n",
    "        audio_analysis_list = []\n",
    "        for i in range(len(song_list)):\n",
    "            results = sp.audio_analysis(song_list[i])\n",
    "            audio_analysis_list.append(results)\n",
    "        track_df = pd.DataFrame(audio_analysis_list)\n",
    "        return track_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_track_info(song_list):\n",
    "        track_info_results = sp.tracks(song_list)\n",
    "        track_info_df = pd.DataFrame(track_info_results['tracks'])\n",
    "        return track_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General functions (not related to Spotify API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stats (column, df):\n",
    "    count_list = []\n",
    "    for row in range(len(df)):\n",
    "        count = 0\n",
    "        for item in range(len(df.iloc[row, column])):\n",
    "            count += 1\n",
    "        count_list.append(count)\n",
    "    return count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function that takes a dataframe and iterates through columns to calculate predicted value\n",
    "\n",
    "def future_value(df, req_feat):\n",
    "    ## Will iterate through columns to calculate future value\n",
    "    requested_df = df[df.feature == req_feat]\n",
    "\n",
    "    x_reg = np.array(requested_df.album_number)\n",
    "    y_reg = np.array(requested_df.value)\n",
    "\n",
    "    fit = np.polyfit(x_reg, y_reg, 1)\n",
    "    fit_fn = np.poly1d(fit) \n",
    "\n",
    "    ## Fit the linear regression model to the expected 14th value\n",
    "    return fit_fn(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to normalize features\n",
    "\n",
    "def feature_norm(df, col):\n",
    "    return(df[col] - df[col].min())/(df[col].max() - df[col].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataframes from API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search for artist by input\n",
    "\n",
    "artist_search_df = sp_search_artist(input(\"What artists would you like to see? \"))\n",
    "\n",
    "## Collect artist id and genres\n",
    "\n",
    "artist_search_id = list(artist_search_df.id)\n",
    "\n",
    "artist_search_genre = list(artist_search_df.genres)\n",
    "artist_search_genre = artist_search_genre[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starting to build album information, then saving off information for later calls\n",
    "\n",
    "album_search_df = sp_search_album(artist_search_id[0])\n",
    "\n",
    "album_name_list = list(album_search_df.name)\n",
    "album_id = list(album_search_df.id)\n",
    "album_release_date = list(album_search_df.release_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Iterating through albums to return a dataframe with track information\n",
    "\n",
    "for i in range(len(album_id)):\n",
    "    if i == 0:\n",
    "        album_track_df = sp_search_track(album_id[i], album_name_list[i], album_release_date[i])\n",
    "    else:\n",
    "        new_track_df = sp_search_track(album_id[i], album_name_list[i], album_release_date[i])\n",
    "        album_track_df = album_track_df.append(new_track_df)\n",
    "        album_track_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Track list will be used to get audio_features and track_analysis for each song        \n",
    "        \n",
    "track_list = list(album_track_df.id)\n",
    "\n",
    "## Audio features for each song\n",
    "\n",
    "for i in range(len(track_list)):\n",
    "    if i == 0:\n",
    "        audio_features_df = sp_features_audio(track_list[i])\n",
    "    else:\n",
    "        new_audio_features_df = sp_features_audio(track_list[i])\n",
    "        audio_features_df = audio_features_df.append(new_audio_features_df)\n",
    "        audio_features_df.reset_index(drop = True, inplace = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Track analysis for each song\n",
    "\n",
    "track_analysis_df = audio_track_analysis(track_list)\n",
    "track_analysis_df.drop(columns = ['meta', 'track'], inplace = True)\n",
    "\n",
    "## Creating counts for each track_analysis record\n",
    "\n",
    "bars_count = count_stats(0, track_analysis_df)\n",
    "beats_count = count_stats(1, track_analysis_df)\n",
    "sections_count = count_stats(2, track_analysis_df)\n",
    "segments_count = count_stats(3, track_analysis_df)\n",
    "tatums_count = count_stats(4, track_analysis_df)\n",
    "\n",
    "audio_df = pd.DataFrame({'bars_count': bars_count, 'beats_count': beats_count, \n",
    "                      'sections_count': sections_count, 'segments_count': segments_count, \n",
    "                      'tatums_count': tatums_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Appending track id numbers to audio analysis\n",
    "\n",
    "track_series = pd.Series(track_list)\n",
    "\n",
    "audio_df = pd.concat([audio_df,track_series], axis = 1)\n",
    "audio_df = audio_df.rename(columns = {0 : 'id'})\n",
    "\n",
    "## Combining audio features and audio analysis features\n",
    "\n",
    "combined_df = pd.merge(album_track_df, audio_features_df, how = 'left', on = 'id')\n",
    "\n",
    "## Renaming columns in merged_df\n",
    "\n",
    "combined_df = combined_df[['href', 'id', 'name', 'track_number', 'album_name', 'release_date',\n",
    "    'acousticness', 'danceability', 'energy', 'instrumentalness', 'key', 'liveness', \n",
    "    'loudness', 'mode', 'speechiness', 'tempo', 'time_signature', 'valence']]\n",
    "\n",
    "audio_df = pd.concat([combined_df, audio_df], axis=1)\n",
    "\n",
    "## Creating a new field for song length (in seconds)\n",
    "\n",
    "song_length = []\n",
    "\n",
    "for i in range(len(album_track_df)):\n",
    "    song_seconds = (album_track_df['duration_ms'][i] / 1000)\n",
    "    song_length.append(song_seconds)\n",
    "\n",
    "## Calculating beats per minute and \n",
    "\n",
    "song_len = pd.Series(song_length)\n",
    "\n",
    "audio_analysis = pd.concat([audio_df, song_len], axis = 1)\n",
    "\n",
    "audio_analysis.rename(columns = {0 : 'song_length_seconds'}, inplace = True)\n",
    "\n",
    "audio_analysis['bpm'] = (audio_analysis['beats_count'] / (audio_analysis['song_length_seconds'] / 60))\n",
    "\n",
    "audio_analysis = audio_analysis.rename(columns = {'name' : 'song_name'})\n",
    "\n",
    "cols_to_use = combined_df.columns.difference(audio_analysis.columns)\n",
    "\n",
    "merged_df = pd.merge(audio_analysis, combined_df[cols_to_use], how = 'left', left_index=True, right_index=True)\n",
    "\n",
    "## Trimming down the audio features that I want to explore initially\n",
    "\n",
    "features_df = combined_df[['release_date', 'album_name', 'name', 'acousticness', 'danceability', 'energy', \n",
    "    'loudness', 'key', 'mode', 'tempo', 'valence']]\n",
    "\n",
    "## Separating the release date into year, month, day columns\n",
    "\n",
    "features_df['year'], features_df['month'], features_df['day'] = features_df['release_date'].str.split('-',2).str\n",
    "\n",
    "## Sort oldest album to newest album\n",
    "\n",
    "features_df = features_df.sort_values(by = ['year', 'month', 'day'])\n",
    "\n",
    "## Reset index and assign unique release dates to a list that will be used in the next loop\n",
    "\n",
    "features_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "unique_release = list(features_df.release_date.unique())\n",
    "\n",
    "## For loop that assigns an album number based on the release date for future plotting\n",
    "\n",
    "album_number = []\n",
    "\n",
    "count = 0\n",
    "record_number = 1\n",
    "\n",
    "for row in range(len(features_df)):\n",
    "    if features_df.release_date.iloc[row] == unique_release[count]:\n",
    "        #print(features_df.release_date.iloc[row], \"-------->\", unique_release[count], \"------->\", features_df.release_date.iloc[row] == unique_release[count])\n",
    "        album_number.append(record_number)\n",
    "    else:\n",
    "        #print('Change Album')\n",
    "        record_number += 1\n",
    "        count += 1\n",
    "        album_number.append(record_number)\n",
    "\n",
    "## Converting resulting list into a dataframe to concat, then renaming the column to show album_number\n",
    "\n",
    "album_number = pd.DataFrame(album_number)\n",
    "\n",
    "features_df = pd.concat([features_df, album_number], axis = 1)\n",
    "\n",
    "features_df.rename(columns = {0 : 'album_number', 'name' : 'song_name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Raw Dataframe for Linear Regression - Song Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_use_2 = merged_df.columns.difference(features_df.columns)\n",
    "\n",
    "raw_features_df = pd.merge(merged_df[cols_to_use_2], features_df, how = 'left', left_on='name', right_on='song_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features_df_2 = raw_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_features_df.to_csv('arctic monkeys.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a melted dataframe for predicting future song features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rearranging columns\n",
    "\n",
    "melted_df = raw_features_df[['release_date',\n",
    "                            'album_number',\n",
    "                            'album_name',\n",
    "                            'track_number',\n",
    "                            'song_name',\n",
    "                            'year',\n",
    "                            'month',\n",
    "                            'day',\n",
    "                            'acousticness',\n",
    "                            'danceability',\n",
    "                            'energy',\n",
    "                            'loudness',\n",
    "                            'valence',\n",
    "                            'song_length_seconds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshaping dataframe to a long format\n",
    "\n",
    "melted_df = pd.melt(melted_df, \n",
    "                   id_vars = ['release_date',\n",
    "                            'album_number',\n",
    "                            'album_name',\n",
    "                            'track_number',\n",
    "                            'song_name',\n",
    "                            'year',\n",
    "                            'month',\n",
    "                            'day'], \n",
    "                   var_name = 'feature', value_name = 'value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing PCA on requested artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing data for plotting\n",
    "\n",
    "feature_col_names = ['acousticness',\n",
    "                     'danceability',\n",
    "                     'energy',\n",
    "                     'loudness',\n",
    "                     'bars_count',\n",
    "                     'beats_count',\n",
    "                     'sections_count',\n",
    "                     'segments_count',\n",
    "                     'tatums_count',\n",
    "                     'song_length_seconds',\n",
    "                     'bpm']\n",
    "\n",
    "## Iterating through columns to normalize the data \n",
    "\n",
    "for i in feature_col_names:\n",
    "    raw_features_df[i] = feature_norm(raw_features_df, i)\n",
    "\n",
    "## Reducing features\n",
    "\n",
    "pca_df = raw_features_df[['album_number',\n",
    "                     'acousticness',\n",
    "                     'danceability',\n",
    "                     'energy',\n",
    "                     'bars_count',\n",
    "                     'sections_count',\n",
    "                     'segments_count',\n",
    "                     'tatums_count',\n",
    "                     'song_length_seconds',\n",
    "                     'bpm']]\n",
    "\n",
    "## Splitting data into target and features\n",
    "\n",
    "y = pca_df['album_number']\n",
    "X_norm = pca_df.iloc[:,1:]\n",
    "\n",
    "## Requesting to use n_compenents that accounts for 95% of variance and applying fit_transform to the model\n",
    "\n",
    "pca = sklearnPCA(n_components = .95)\n",
    "transformed = pd.DataFrame(pca.fit_transform(X_norm))\n",
    "\n",
    "## Print statements to show the impact of each feature\n",
    "\n",
    "pca_len = len(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis - Requested Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining 4 components for LDA and applying fit_transform\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components = pca_len)\n",
    "transformed_lda = pd.DataFrame(lda.fit_transform(X_norm, y))\n",
    "\n",
    "## Defining 4 components for LDA and applying fit_transform\n",
    "\n",
    "tsne = TSNE(n_components = 2, perplexity = 80, learning_rate = 850)\n",
    "transformed_tsne = pd.DataFrame(tsne.fit_transform(transformed_lda))\n",
    "\n",
    "## Creating new df for interactive Bokeh graphs\n",
    "\n",
    "tsne_df = pd.concat([raw_features_df[['album_name', 'song_name', 'album_number']], transformed_tsne.iloc[:,:2]], axis=1, join_axes=[raw_features_df.index])\n",
    "\n",
    "tsne_df.rename(columns = {0 : 'x', 1 : 'y'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE Plot - Requested Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resetting the html output to prevent multiple graphs from showing up\n",
    "\n",
    "bpl.reset_output()\n",
    "\n",
    "## Hover tool set to show album number, album name and song name\n",
    "\n",
    "hover = bmo.HoverTool(\n",
    "    tooltips = [\n",
    "        ('Album #: ', '@album_number'),\n",
    "        ('Album Name: ', '@album_name'),\n",
    "        ('Song Name: ', '@song_name')])\n",
    "\n",
    "## Configuring tools that will be used in the plot (plot size is large for viewing on monitor and not laptop)\n",
    "\n",
    "p = figure(tools = [hover, \"box_select, box_zoom, lasso_select, reset\"], plot_width = 1200, plot_height = 800,  toolbar_location = 'above')\n",
    "\n",
    "## Removing all lines and text, since location on the grid doesn't add any information for analysis\n",
    "\n",
    "p.xaxis.major_tick_line_color = None\n",
    "p.xaxis.minor_tick_line_color = None\n",
    "p.xaxis.axis_line_color = None\n",
    "p.xaxis.major_label_text_font_size = '0pt'\n",
    "\n",
    "p.yaxis.major_tick_line_color = None\n",
    "p.yaxis.minor_tick_line_color = None\n",
    "p.yaxis.axis_line_color = None\n",
    "p.yaxis.major_label_text_font_size = '0pt'\n",
    "\n",
    "p.grid.visible = False\n",
    "\n",
    "## Creating color palette/map\n",
    "\n",
    "palette = d3['Category20'][len(tsne_df['album_name'].unique())]\n",
    "color_map = bmo.CategoricalColorMapper(factors = tsne_df['album_name'].unique(), palette = palette) \n",
    "\n",
    "p.background_fill_color = '#2c3134'\n",
    "p.background_fill_alpha = 0.5\n",
    "\n",
    "## Creating plots and legend information\n",
    "\n",
    "plot_names = []\n",
    "legend_list = []\n",
    "\n",
    "for i in range(len(album_name_list)):\n",
    "    plot_names.append(\"tsne_plot_\" + str(i))\n",
    "     \n",
    "for j in range(len(plot_names)):\n",
    "    plot_names[j] = p.circle(x = 'x', y = 'y', source = tsne_df[tsne_df.album_name == album_name_list[j]], color = palette[j], \n",
    "                        size = 6, alpha = 0.75, muted_color = palette[j], muted_alpha = 0.1)\n",
    "    legend_list.append((album_name_list[j], [plot_names[j]]))\n",
    "    \n",
    "legend = Legend(items = legend_list, location = (0,30))\n",
    "\n",
    "p.add_layout(legend, 'right')\n",
    "p.legend.click_policy = 'mute'\n",
    "\n",
    "## Show the Results\n",
    "\n",
    "output_file(\"TSNE_plot.html\")\n",
    "bpl.output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting future album features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a key:value dictionary pair from the unique features\n",
    "## This will be used by spotify to recommend similar songs to our predicted values\n",
    "\n",
    "keys = []\n",
    "values = []\n",
    "\n",
    "unique_feat_list = list(melted_df.feature.unique())\n",
    "\n",
    "for i in unique_feat_list:\n",
    "    keys.append(i)\n",
    "    values.append(future_value(melted_df, i))\n",
    "\n",
    "pred_dicts = dict(zip(keys, values))\n",
    "\n",
    "## Spotify asks for the recommended song length in ms\n",
    "\n",
    "pred_dicts['song_length_seconds'] = round(pred_dicts['song_length_seconds']*1000)\n",
    "\n",
    "## Uses the artist seed and predicted values to return songs that are similiar\n",
    "\n",
    "results = sp.recommendations(seed_artists = artist_search_id, limit = 10,\n",
    "                                     target_acousticness = pred_dicts['acousticness'],\n",
    "                                     target_danceability = pred_dicts['danceability'],\n",
    "                                     target_energy = pred_dicts['energy'],\n",
    "                                     target_loudness = pred_dicts['loudness'],\n",
    "                                     target_target_duration_ms = pred_dicts['song_length_seconds'],\n",
    "                                     target_valence = pred_dicts['valence'])\n",
    "\n",
    "## Unpack values and create a dataframe\n",
    "\n",
    "results = results['tracks']\n",
    "\n",
    "recommend_df = pd.DataFrame(results)\n",
    "\n",
    "## Taking the track ID for additional analysis, plus the song popularity to incorporate popular areas to move into\n",
    "\n",
    "recommended_tracks = []\n",
    "popularity = []\n",
    "\n",
    "for i in range(len(recommend_df)):\n",
    "    recommended_tracks.append(recommend_df.uri[i])\n",
    "    popularity.append(recommend_df.popularity[i])\n",
    "\n",
    "## Call function and store audio features from recommended songs into a dataframe\n",
    "\n",
    "recommend_audio_feat = sp_features_audio(recommended_tracks)\n",
    "\n",
    "## Call function and store audio track features from recommended songs into a dataframe\n",
    "\n",
    "recommend_track_analysis = audio_track_analysis(recommended_tracks)\n",
    "\n",
    "## Creating counts for each track_analysis record\n",
    "\n",
    "bars_count_rec = count_stats(0, recommend_track_analysis)\n",
    "beats_count_rec = count_stats(1, recommend_track_analysis)\n",
    "sections_count_rec = count_stats(2, recommend_track_analysis)\n",
    "segments_count_rec = count_stats(3, recommend_track_analysis)\n",
    "tatums_count_rec = count_stats(4, recommend_track_analysis)\n",
    "\n",
    "audio_df_recommend = pd.DataFrame({'bars_count': bars_count, 'beats_count': beats_count, \n",
    "                      'sections_count': sections_count, 'segments_count': segments_count, \n",
    "                      'tatums_count': tatums_count})\n",
    "\n",
    "## Creating a new field for song length (in seconds)\n",
    "\n",
    "song_length_rec = []\n",
    "\n",
    "for i in range(len(recommend_audio_feat)):\n",
    "    song_seconds_rec = (recommend_audio_feat['duration_ms'][i] / 1000)\n",
    "    song_length_rec.append(song_seconds_rec)\n",
    "\n",
    "## Calculating beats per minute and \n",
    "\n",
    "song_len_rec = pd.Series(song_length_rec)\n",
    "\n",
    "song_len_rec = song_len_rec.rename('song_length_seconds')\n",
    "\n",
    "audio_analysis_rec = pd.concat([audio_df_recommend, song_len_rec], axis = 1)\n",
    "\n",
    "audio_analysis_rec['bpm'] = (audio_analysis_rec['beats_count'] / (audio_analysis_rec['song_length_seconds'] / 60))\n",
    "\n",
    "## Merge track analysis and audio features, then append an album \n",
    "\n",
    "raw_df_recommend = pd.merge(recommend_audio_feat, audio_analysis_rec, how = 'left', left_index = True, right_index = True)\n",
    "raw_df_recommend['album_number'] = len(raw_features_df.album_number.unique()) + 1\n",
    "\n",
    "raw_df_recommend['spotify_link'] = 'https://embed.spotify.com/?uri=spotify:track:' + raw_df_recommend.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popular Albums in the Same Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uses the artist seed and predicted values to return songs that are similiar\n",
    "\n",
    "results = sp.recommendations(seed_artists = artist_search_id, limit = 10, min_popularity = 75,\n",
    "                                     target_acousticness = pred_dicts['acousticness'],\n",
    "                                     target_danceability = pred_dicts['danceability'],\n",
    "                                     target_energy = pred_dicts['energy'],\n",
    "                                     target_loudness = pred_dicts['loudness'],\n",
    "                                     target_target_duration_ms = pred_dicts['song_length_seconds'],\n",
    "                                     target_valence = pred_dicts['valence'])\n",
    "\n",
    "## Unpack values and create a dataframe\n",
    "\n",
    "results = results['tracks']\n",
    "\n",
    "recommend_df = pd.DataFrame(results)\n",
    "\n",
    "## Taking the track ID for additional analysis, plus the song popularity to incorporate popular areas to move into\n",
    "\n",
    "recommended_tracks = []\n",
    "popularity = []\n",
    "\n",
    "for i in range(len(recommend_df)):\n",
    "    recommended_tracks.append(recommend_df.uri[i])\n",
    "    popularity.append(recommend_df.popularity[i])\n",
    "  \n",
    "\n",
    "  \n",
    "## Creating a popularity Series for plotting\n",
    "\n",
    "popularity_series = pd.Series(popularity)\n",
    "popularity_series = popularity_series.rename(\"popularity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(raw_df_recommend)):\n",
    "    print('https://embed.spotify.com/?uri=' + recommended_tracks[i], \" ---------> \", popularity[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling data for recommendations for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Audio features for each song\n",
    "\n",
    "for i in range(len(recommended_tracks)):\n",
    "    if i == 0:\n",
    "        rec_audio_features_df = sp_features_audio(recommended_tracks[i])\n",
    "    else:\n",
    "        rec_new_audio_features_df = sp_features_audio(recommended_tracks[i])\n",
    "        rec_audio_features_df = rec_audio_features_df.append(rec_new_audio_features_df)\n",
    "        rec_audio_features_df.reset_index(drop = True, inplace = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Track analysis for each song\n",
    "\n",
    "rec_track_analysis_df = audio_track_analysis(recommended_tracks)\n",
    "rec_track_analysis_df.drop(columns = ['meta', 'track'], inplace = True)\n",
    "\n",
    "## Creating counts for each track_analysis record\n",
    "\n",
    "bars_count = count_stats(0, rec_track_analysis_df)\n",
    "beats_count = count_stats(1, rec_track_analysis_df)\n",
    "sections_count = count_stats(2, rec_track_analysis_df)\n",
    "segments_count = count_stats(3, rec_track_analysis_df)\n",
    "tatums_count = count_stats(4, rec_track_analysis_df)\n",
    "\n",
    "rec_audio_df = pd.DataFrame({'bars_count': bars_count, 'beats_count': beats_count, \n",
    "                      'sections_count': sections_count, 'segments_count': segments_count, \n",
    "                      'tatums_count': tatums_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combining audio features and audio analysis features\n",
    "\n",
    "rec_combined_df = pd.merge(rec_audio_df, rec_audio_features_df, how = 'left', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calulating song length seconds\n",
    "\n",
    "rec_combined_df['song_length_seconds'] = (rec_combined_df['duration_ms'] / 1000) \n",
    "\n",
    "## Calculating beats per minute\n",
    "\n",
    "rec_combined_df['bpm'] = (rec_combined_df['beats_count'] / (rec_combined_df['song_length_seconds'] / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_combined_df_2 = rec_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pulling song titles for recommended titles\n",
    "\n",
    "rec_song_titles = sp_track_info(recommended_tracks)\n",
    "\n",
    "rec_song_titles = rec_song_titles['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing - Recommended Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing data for plotting\n",
    "\n",
    "rec_feature_col_names = ['acousticness',\n",
    "                     'danceability',\n",
    "                     'energy',\n",
    "                     'loudness',\n",
    "                     'bars_count',\n",
    "                     'beats_count',\n",
    "                     'sections_count',\n",
    "                     'segments_count',\n",
    "                     'tatums_count',\n",
    "                     'song_length_seconds',\n",
    "                     'bpm']\n",
    "\n",
    "## Iterating through columns to normalize the data \n",
    "\n",
    "for i in rec_feature_col_names:\n",
    "    rec_combined_df[i] = feature_norm(rec_combined_df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing data for plotting\n",
    "\n",
    "feature_col_names = ['acousticness',\n",
    "                     'danceability',\n",
    "                     'energy',\n",
    "                     'loudness',\n",
    "                     'bars_count',\n",
    "                     'beats_count',\n",
    "                     'sections_count',\n",
    "                     'segments_count',\n",
    "                     'tatums_count',\n",
    "                     'song_length_seconds',\n",
    "                     'bpm']\n",
    "\n",
    "## Iterating through columns to normalize the data \n",
    "\n",
    "for i in feature_col_names:\n",
    "    raw_features_df[i] = feature_norm(raw_features_df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features_merge = raw_features_df.drop(columns = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_combined_df = rec_combined_df.rename(columns = {'name' : 'song_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_normalization = pd.concat([rec_combined_df,raw_features_merge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalizing data for plotting\n",
    "\n",
    "feature_col_names = ['acousticness',\n",
    "                     'danceability',\n",
    "                     'energy',\n",
    "                     'loudness',\n",
    "                     'bars_count',\n",
    "                     'beats_count',\n",
    "                     'sections_count',\n",
    "                     'segments_count',\n",
    "                     'tatums_count',\n",
    "                     'song_length_seconds',\n",
    "                     'bpm']\n",
    "\n",
    "## Iterating through columns to normalize the data \n",
    "\n",
    "for i in feature_col_names:\n",
    "    combined_normalization[i] = feature_norm(combined_normalization, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features_df[raw_features_df.name == \"Why'd You Only Call Me When You're High?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_combined_df_2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## PCA - Recommended tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reducing features\n",
    "\n",
    "rec_pca_df = combined_normalization[[\n",
    "                     'acousticness',\n",
    "                     'danceability',\n",
    "                     'energy',\n",
    "                     'bars_count',\n",
    "                     'sections_count',\n",
    "                     'segments_count',\n",
    "                     'tatums_count',\n",
    "                     'song_length_seconds',\n",
    "                     'bpm']]\n",
    "\n",
    "## Adding \"album_number\" to match what I used in the original fitting\n",
    "rec_pca_df['album_number'] = 'Popular Song'\n",
    "\n",
    "## Splitting data into target and features\n",
    "\n",
    "rec_y = rec_pca_df['album_number']\n",
    "rec_X_norm = rec_pca_df.iloc[:,:-1]\n",
    "\n",
    "## Transforming using previously-fit PCA model\n",
    "\n",
    "rec_transformed = pd.DataFrame(pca.transform(rec_X_norm))\n",
    "\n",
    "## Print statements to show the impact of each feature\n",
    "\n",
    "pca_len = len(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA & TSNE - Recommended Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transforming using previously-fit LDA model\n",
    "\n",
    "rec_transformed_lda = pd.DataFrame(lda.transform(rec_X_norm))\n",
    "\n",
    "## Defining 4 components for LDA and applying fit_transform\n",
    "\n",
    "rec_transformed_tsne = pd.DataFrame(tsne.fit_transform(rec_transformed_lda))\n",
    "\n",
    "## Creating new df for interactive Bokeh graphs\n",
    "\n",
    "rec_tsne_df = pd.concat([rec_transformed_tsne.iloc[:,:2]], axis=1, join_axes=[rec_combined_df.index])\n",
    "\n",
    "rec_tsne_df.rename(columns = {0 : 'x', 1 : 'y'}, inplace = True)\n",
    "\n",
    "# ## Appending popularity\n",
    "\n",
    "# rec_tsne_df = pd.concat([rec_tsne_df, popularity_series], axis = 1)\n",
    "\n",
    "## Appending song name\n",
    "\n",
    "rec_tsne_df = pd.concat([rec_tsne_df, rec_song_titles], axis = 1)\n",
    "rec_tsne_df = rec_tsne_df.rename(columns = {'name' : 'song_name'})\n",
    "\n",
    "## Creating album name for recommended songs\n",
    "\n",
    "rec_tsne_df['album_name'] = 'Recommended Popular Song'\n",
    "\n",
    "# Creating album name for recommended songs\n",
    "\n",
    "rec_tsne_df['album_number'] = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_tsne_df = tsne_df.append(rec_tsne_df)\n",
    "\n",
    "overlay_album_list = list(overlay_tsne_df.album_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_tsne_df[overlay_tsne_df.song_name == \"Why'd You Only Call Me When You're High?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting TSNE with Recommended Tracks overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resetting the html output to prevent multiple graphs from showing up\n",
    "\n",
    "bpl.reset_output()\n",
    "\n",
    "## Hover tool set to show album number, album name and song name\n",
    "\n",
    "hover = bmo.HoverTool(\n",
    "    tooltips = [\n",
    "        ('Album #: ', '@album_number'),\n",
    "        ('Album Name: ', '@album_name'),\n",
    "        ('Song Name: ', '@song_name')])\n",
    "\n",
    "## Configuring tools that will be used in the plot (plot size is large for viewing on monitor and not laptop)\n",
    "\n",
    "p = figure(tools = [hover, \"box_select, box_zoom, lasso_select, reset\"], plot_width = 1200, plot_height = 800,  toolbar_location = 'above')\n",
    "\n",
    "## Removing all lines and text, since location on the grid doesn't add any information for analysis\n",
    "\n",
    "p.xaxis.major_tick_line_color = None\n",
    "p.xaxis.minor_tick_line_color = None\n",
    "p.xaxis.axis_line_color = None\n",
    "p.xaxis.major_label_text_font_size = '0pt'\n",
    "\n",
    "p.yaxis.major_tick_line_color = None\n",
    "p.yaxis.minor_tick_line_color = None\n",
    "p.yaxis.axis_line_color = None\n",
    "p.yaxis.major_label_text_font_size = '0pt'\n",
    "\n",
    "p.grid.visible = False\n",
    "\n",
    "## Creating color palette/map\n",
    "\n",
    "palette = d3['Category20'][len(overlay_tsne_df['album_name'].unique())]\n",
    "color_map = bmo.CategoricalColorMapper(factors = overlay_tsne_df['album_name'].unique(), palette = palette) \n",
    "\n",
    "p.background_fill_color = '#2c3134'\n",
    "p.background_fill_alpha = 0.5\n",
    "\n",
    "## Creating plots and legend information\n",
    "\n",
    "plot_names = []\n",
    "legend_list = []\n",
    "\n",
    "for i in range(len(overlay_album_list)):\n",
    "    plot_names.append(\"tsne_plot_\" + str(i))\n",
    "     \n",
    "for j in range(len(plot_names)):\n",
    "    plot_names[j] = p.circle(x = 'x', y = 'y', source = overlay_tsne_df[overlay_tsne_df.album_name == overlay_album_list[j]], color = palette[j], \n",
    "                        size = 6, alpha = 0.75, muted_color = palette[j], muted_alpha = 0.1)\n",
    "    legend_list.append((overlay_album_list[j], [plot_names[j]]))\n",
    "    \n",
    "legend = Legend(items = legend_list, location = (0,30))\n",
    "\n",
    "p.add_layout(legend, 'right')\n",
    "p.legend.click_policy = 'mute'\n",
    "\n",
    "## Show the Results\n",
    "\n",
    "output_file(\"Reccomended_song_TSNE_plot.html\")\n",
    "bpl.output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap Work Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio_df.head()\n",
    "    \n",
    "audio_df[audio_df.name == \"Why'd You Only Call Me When You're High?\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_track_search = sp.search(q = recommended_tracks[0], limit = 1, type = 'track')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_track_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
