{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "## Basic Packages\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "## Import NLTK packages\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk import wordpunct_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "## Import Gensim packages\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "## Notebook display settings\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df = pd.read_csv('data//lyric_data.csv', encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatles_lyrics = lyrics_df[lyrics_df.artist == 'The Beatles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\pandas\\core\\frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "beatles_lyrics.drop(columns = ['link'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatles_lyrics.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\pandas\\core\\frame.py:3778: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "beatles_lyrics.rename(columns = {'text' : 'lyrics'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatles_lyrics.to_csv('data//beatles_lyrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a list of lyrics\n",
    "\n",
    "stripped_lyrics = beatles_lyrics.lyrics.values.tolist()\n",
    "stripped_lyrics = [x.lower() for x in stripped_lyrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning up the text - removing new lines, extra spaces, random characters\n",
    "\n",
    "stripped_lyrics = [re.sub('\\n', '', sent) for sent in stripped_lyrics]\n",
    "stripped_lyrics = [re.sub('\\s{2,}', ' ', sent) for sent in stripped_lyrics]\n",
    "stripped_lyrics = [re.sub(\"\\\\\\'\", '', sent) for sent in stripped_lyrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stripped_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing a stop word list and including a few extra words\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['hey', 'nah', '[chorus]', 'la'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenizing the lyrics in each song using RegexpTokenizer and removing stop words\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "porter = PorterStemmer()\n",
    "\n",
    "token_list = []\n",
    "\n",
    "for i in range(len(stripped_lyrics)):   \n",
    "    tokenized_list = []\n",
    "    tokenized_list = tokenizer.tokenize(stripped_lyrics[i])\n",
    "    tokenized_list = [i for i in tokenized_list if i not in stop_words]\n",
    "    tokenized_list = [porter.stem(tokens) for tokens in tokenized_list]\n",
    "    token_list.append(tokenized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\gensim\\models\\phrases.py:494: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(token_list, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[token_list], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words_bigrams = make_bigrams(token_list)\n",
    "data_words_trigrams = make_trigrams(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 2), (1, 1), (2, 3), (3, 4), (4, 3), (5, 2), (6, 3), (7, 1), (8, 3), (9, 1), (10, 3), (11, 3), (12, 6), (13, 1), (14, 1), (15, 3), (16, 1), (17, 14), (18, 3), (19, 2), (20, 1), (21, 1), (22, 1), (23, 5), (24, 3), (25, 1), (26, 2), (27, 3), (28, 2), (29, 1), (30, 1), (31, 3), (32, 1), (33, 1), (34, 1), (35, 7), (36, 2), (37, 3), (38, 3), (39, 3), (40, 4), (41, 5), (42, 3), (43, 1), (44, 5), (45, 1), (46, 8), (47, 1), (48, 1), (49, 3), (50, 3), (51, 1), (52, 9), (53, 3), (54, 3)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words_trigrams)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_words_trigrams\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=15, \n",
    "                                           random_state=45,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=100,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.057*\"im\" + 0.048*\"good\" + 0.045*\"day\" + 0.045*\"know\" + 0.036*\"lie\" + '\n",
      "  '0.029*\"love\" + 0.028*\"way\" + 0.027*\"she\" + 0.024*\"thing\" + 0.024*\"said\"'),\n",
      " (1,\n",
      "  '0.067*\"dont\" + 0.036*\"im\" + 0.025*\"got\" + 0.024*\"get\" + 0.022*\"know\" + '\n",
      "  '0.022*\"girl\" + 0.018*\"come\" + 0.018*\"your\" + 0.018*\"ive\" + 0.017*\"cant\"'),\n",
      " (2,\n",
      "  '0.073*\"go\" + 0.069*\"let\" + 0.043*\"come\" + 0.024*\"take\" + 0.023*\"johnni\" + '\n",
      "  '0.021*\"chang\" + 0.021*\"world\" + 0.018*\"youll\" + 0.015*\"may\" + '\n",
      "  '0.015*\"gonna\"'),\n",
      " (3,\n",
      "  '0.031*\"home\" + 0.023*\"time\" + 0.022*\"troubl\" + 0.020*\"like\" + 0.019*\"knew\" '\n",
      "  '+ 0.019*\"commonwealth\" + 0.018*\"your\" + 0.018*\"christma\" + 0.017*\"year\" + '\n",
      "  '0.017*\"feel\"'),\n",
      " (4,\n",
      "  '0.155*\"yeah\" + 0.062*\"babi\" + 0.047*\"oh\" + 0.032*\"got\" + 0.029*\"well\" + '\n",
      "  '0.020*\"feel\" + 0.018*\"come\" + 0.016*\"ah\" + 0.016*\"long\" + 0.011*\"wo\"'),\n",
      " (5,\n",
      "  '0.064*\"im\" + 0.021*\"sleep\" + 0.020*\"night\" + 0.020*\"mind\" + 0.019*\"leav\" + '\n",
      "  '0.018*\"told\" + 0.016*\"mayb\" + 0.016*\"didnt\" + 0.015*\"gonna\" + 0.014*\"wait\"'),\n",
      " (6,\n",
      "  '0.039*\"want\" + 0.024*\"john\" + 0.018*\"see\" + 0.017*\"danc\" + 0.015*\"let\" + '\n",
      "  '0.014*\"hold\" + 0.014*\"bad\" + 0.014*\"ye\" + 0.013*\"brian\" + 0.013*\"think\"'),\n",
      " (7,\n",
      "  '0.040*\"aint\" + 0.035*\"well\" + 0.031*\"bring\" + 0.027*\"sun\" + 0.025*\"oh\" + '\n",
      "  '0.024*\"bonni\" + 0.023*\"babi\" + 0.021*\"glad\" + 0.019*\"back\" + 0.019*\"she\"'),\n",
      " (8,\n",
      "  '0.070*\"mine\" + 0.068*\"hand\" + 0.032*\"boy\" + 0.025*\"get\" + 0.022*\"talk\" + '\n",
      "  '0.022*\"bop_shuop\" + 0.021*\"say\" + 0.017*\"girl\" + 0.017*\"hide\" + '\n",
      "  '0.017*\"well\"'),\n",
      " (9,\n",
      "  '0.052*\"man\" + 0.046*\"cri\" + 0.040*\"babi\" + 0.038*\"want\" + 0.033*\"tri\" + '\n",
      "  '0.025*\"keep\" + 0.018*\"sit\" + 0.016*\"old\" + 0.016*\"your\" + 0.014*\"there\"'),\n",
      " (10,\n",
      "  '0.054*\"get\" + 0.046*\"back\" + 0.045*\"call\" + 0.040*\"much\" + 0.035*\"time\" + '\n",
      "  '0.023*\"buy\" + 0.020*\"julia\" + 0.017*\"girl\" + 0.017*\"see\" + 0.016*\"tonight\"'),\n",
      " (11,\n",
      "  '0.032*\"im\" + 0.021*\"komm_gib_mir_dein\" + 0.021*\"anyth\" + 0.015*\"oh\" + '\n",
      "  '0.013*\"loser\" + 0.013*\"molli\" + 0.013*\"komm\" + 0.012*\"blue_sued_shoe\" + '\n",
      "  '0.012*\"desmond\" + 0.012*\"harp\"'),\n",
      " (12,\n",
      "  '0.060*\"say\" + 0.057*\"want\" + 0.056*\"that\" + 0.039*\"hello\" + 0.032*\"goodby\" '\n",
      "  '+ 0.026*\"ever\" + 0.023*\"know\" + 0.021*\"ye\" + 0.020*\"die\" + 0.020*\"gonna\"'),\n",
      " (13,\n",
      "  '0.151*\"love\" + 0.046*\"ill\" + 0.036*\"oh\" + 0.032*\"need\" + 0.031*\"im\" + '\n",
      "  '0.028*\"know\" + 0.017*\"one\" + 0.017*\"true\" + 0.016*\"never\" + 0.015*\"make\"'),\n",
      " (14,\n",
      "  '0.052*\"pleas\" + 0.049*\"long\" + 0.047*\"togeth\" + 0.040*\"dont\" + 0.034*\"help\" '\n",
      "  '+ 0.025*\"tree\" + 0.021*\"day\" + 0.020*\"way\" + 0.018*\"find\" + 0.012*\"like\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
